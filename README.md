# Project Overview
This project demonstrates a speech recognition system that records audio, converts it to text, and compares the transcript to a predefined set of exam questions. The system utilizes Google’s Speech Recognition API to transcribe spoken language and then analyzes the transcribed text to find common words between the transcript and the exam questions. The analysis involves audio processing, text tokenization, and filtering out stopwords using Natural Language Processing (NLP) techniques in Python.

**`The project is still a work in progress`**, with ongoing efforts to make it real-time and incorporate transformer models to detect the intent or context behind the student’s speech during the exam. Currently, the system focuses on identifying the intersection of keywords between the student's speech and the exam questions.

## Table of Contents
- Project Overview
- Features
- Prerequisites
- Project Structure
- How It Works
  1. Audio Recording
  2. Speech Recognition
  3. Text Processing
- File Requirements
- How to Run
- Example Output
- Future Enhancements

## Features
- **Real-time Audio Recording**: Records audio input using PyAudio.
- **Speech Recognition**: Transcribes recorded audio using Google's SpeechRecognition API.
- **Text Processing**: Uses the NLTK library to tokenize words and remove stopwords.
- **Text Comparison**: Compares transcribed speech to predefined Python theory exam questions to find common words.
- **Multi-threading**: Records audio in parallel segments for efficient processing.

## Prerequisites
Before running the project, ensure that you have the following installed:
- Python 3.x
- Required Python Libraries (Install using pip): `SpeechRecognition`, `PyAudio`, `nltk`, `wave`, `threading`
- Internet connection (for Google SpeechRecognition API)
- NLTK stopwords corpus (run `nltk.download('stopwords')` in Python)

To install the required libraries, you can use:
```bash
pip install SpeechRecognition pyaudio nltk
```

## How It Works
This project involves three key steps:

### 1. Audio Recording
The project records audio using the pyaudio library. The record_audio function captures audio from your device's microphone and stores it as a WAV file. Each recording is segmented for parallel processing.

### 2. Speech Recognition
Once the audio is recorded, the system uses Google’s Speech Recognition API via the SpeechRecognition library to convert the audio to text. Each transcribed text is appended to test.txt.

### 3. Text Processing
The project uses the Natural Language Toolkit (NLTK) to tokenize the transcribed text and remove common stopwords (e.g., "the", "is", "in"). The cleaned text from test.txt is compared against the predefined Python theory exam questions in paper.txt to identify overlapping key terms.

## File Requirements
Before running the project, ensure you have two text files:

**test.txt:** This file will contain the text transcribed from the recorded audio. (Automatically generated by the script)
**paper.txt:** This file should contain the exam questions or reference text against which the transcribed content is compared. Example content can be found in the sample paper.txt provided in this project.
**Example of paper.txt:**

```txt

1. Explain the key features of Python and why it is considered a high-level language.
2. Discuss the significance of Python's standard library and give examples of commonly used modules.
3. Describe the different programming paradigms supported by Python and provide examples for each.
```

## How to Run
Clone this repository or download the source code:

``` bash
git clone https://github.com/Jaya-Prakash-17/voice-activity-detection-for-proctoring.git
cd speech-recognition-exam
```
## Install the required dependencies:
```
bash
pip install -r requirements.txt
```
## Download NLTK stopwords:

```bash

python -c "import nltk; nltk.download('stopwords')"
```

## Run the script:

```bash
python main.py
```
## The program will:

1. Record your voice in 10-second segments.
2. Convert the audio into text and store it in test.txt.
3. Process the text, filter out stopwords, and compare it with the predefined questions in paper.txt.
4. Print out the common words between the two texts.
## Example Output
```bash

Recording audio segment 1...
Recording audio segment 2...
Recording audio segment 3...

Number of common words: 5
Common words: {'Python', 'functions', 'library', 'data', 'structures'}
```
This output shows how many words were shared between the recorded transcript and the exam questions. In this case, words like "Python," "functions," and "data" appear in both the transcribed speech and the exam questions.

## Future Enhancements
1. **Real-time transcription feedback:** Display recognized text as it is transcribed.  
2. **Graphical User Interface (GUI):** Develop a user-friendly interface to handle recordings and show comparisons.  
3. **Advanced NLP Techniques:** Implement lemmatization and stemming to enhance the accuracy of text comparisons.  
4. **Multiple Language Support:** Extend the project to support multiple languages for transcription.
